name: Deploy openDAQ SDK packages on AWS

on:
  workflow_dispatch:

  push:
    branches: [main]

env:
  cmake_preset: package
  package_path: ${{ github.workspace }}/build/_packages
  wheels_path: ${{ github.workspace }}/build/wheels
  package_path_rel: build/_packages # WA for https://github.com/actions/checkout/issues/785
  s3bucket: bb-blueberry-sdk-releases
  s3path: releases/${{ github.ref_name }}/SDK
  s3wheels_linux_x86_64_path: releases/${{ github.ref_name }}/Python Wheels (Linux x86_64)
  s3wheels_win_amd64_path: releases/${{ github.ref_name }}/Python Wheels (Windows amd64)
  s3docpath: releases/${{ github.ref_name }}/Specifications and documentation
  s3simulatorpath: releases/${{ github.ref_name }}/Simulator
  vm_name: device_simulator
  simulator_app_artifact: SimulatorApp
  simulator_package_artifact: SimulatorPackage
  python_version_build: 3.11
  python_versions: 3.8 3.9 3.10 3.11 3.12

jobs:
  deploy_windows:
    runs-on: ${{ matrix.runner }}
    name: ${{ matrix.name }}

    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.name }}
      cancel-in-progress: true
    timeout-minutes: 180
    strategy:
      fail-fast: false
      matrix:
        # https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners
        include:
          - name: Windows VS 2022 x64 Release
            runner: windows-latest
            cmake_generator: "Visual Studio 17 2022"
            cmake_generator_platform: x64
            cmake_build_type: Release
            cmake_defines: -DOPENDAQ_MSVC_SINGLE_PROCESS_BUILD=ON
            cpack: NSIS
          - name: Windows VS 2022 Win32 Release
            runner: windows-latest
            cmake_generator: "Visual Studio 17 2022"
            cmake_generator_platform: Win32
            cmake_build_type: Release
            cmake_defines: -DOPENDAQ_GENERATE_PYTHON_BINDINGS=OFF -DOPENDAQ_MSVC_SINGLE_PROCESS_BUILD=ON
            cpack: NSIS

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configure and build Wheels
        if: matrix.cmake_generator_platform != 'Win32'
        run: |
          mkdir build
          cd build
          mkdir wheels
          $versions = "${{ env.python_versions }}".split(" ")
          foreach ($version in $versions) {
            Write-Output "Building for Python $version"
            cmake -G "${{ matrix.cmake_generator }}" -A ${{ matrix.cmake_generator_platform }} --preset ${{ env.cmake_preset }} ${{ matrix.cmake_defines }} -DCI_GIT_BRANCH=${{ github.ref }} -DCMAKE_BUILD_TYPE=${{ matrix.cmake_build_type }} "-DOPENDAQ_PYTHON_VERSION=$version" ..
            cmake --build . --config ${{ matrix.cmake_build_type }}
            Write-Output "Creating virtual environment for Python $version"
            Invoke-Expression "py -$version -m venv venv"
            ./venv/Scripts/activate
            pip install numpy pybind11-stubgen
            $remove_python_module_flag = "-r"
            if ($version -eq $versions[-1]) {
              $remove_python_module_flag = $null
            }
            Invoke-Expression "py -${{env.python_version_build}} ../bindings/python/package/build_pip.py -l bin/${{ matrix.cmake_build_type }} $remove_python_module_flag"
            Copy-Item pip/packages/*.whl wheels
            deactivate
            Remove-Item venv -Recurse
          }

      - name: Configure and build without Wheels
        if: matrix.cmake_generator_platform == 'Win32'
        run: |
          mkdir build
          cd build
          Write-Output "Building for Win32"
          cmake -G "${{ matrix.cmake_generator }}" -A ${{ matrix.cmake_generator_platform }} --preset ${{ env.cmake_preset }} ${{ matrix.cmake_defines }} -DCI_GIT_BRANCH=${{ github.ref }} -DCMAKE_BUILD_TYPE=${{ matrix.cmake_build_type }} ..
          cmake --build . --config ${{ matrix.cmake_build_type }}

      - name: Package
        working-directory: build
        run: cpack -C ${{ matrix.cmake_build_type }} -G ${{ matrix.cpack }}

      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Get short SHA
        if: github.ref == 'refs/heads/main'
        id: short-sha
        uses: benjlevesque/short-sha@v2.2

      - name: Rename package
        shell: pwsh
        working-directory: ${{ env.package_path }}
        run: |
           Get-ChildItem -Path .\* -Include *.exe | Rename-Item -NewName {$_.FullName.ToLower()}

      - name: Rename package (main)
        if: github.ref == 'refs/heads/main'
        shell: pwsh
        working-directory: ${{ env.package_path }}
        run: |
           Get-ChildItem -Path .\* -Include *.exe | Rename-Item -NewName {$_.BaseName + '_${{ steps.short-sha.outputs.sha }}' + $_.Extension}

      - name: Rename wheels (main)
        if: github.ref == 'refs/heads/main' && matrix.cmake_generator_platform != 'Win32'
        shell: pwsh
        working-directory: ${{ env.wheels_path }}
        run: |
          foreach($pckg in Get-ChildItem -Filter *.whl -Path .) {
            $pckg_split = $pckg.Name.split("-")
            $pckg_split[1] = $pckg_split[1] + "_${{ steps.short-sha.outputs.sha }}"
            $renamed = $pckg_split -Join "-"
            Rename-Item -Path $pckg -NewName $renamed
          }

      - name: Upload package to S3
        working-directory: ${{ env.package_path }}
        run: |
          aws s3 rm "s3://${{ env.s3bucket }}/${{ env.s3path }}/" --recursive --exclude '*' --include '*.exe'
          aws s3 cp . "s3://${{ env.s3bucket }}/${{ env.s3path }}/" --recursive

      - name: Upload Wheels to S3
        if: github.ref == 'refs/heads/main' && matrix.cmake_generator_platform != 'Win32'
        working-directory: ${{ env.wheels_path }}
        run: |
          aws s3 rm "s3://${{ env.s3bucket }}/${{ env.s3wheels_win_amd64_path }}" --recursive --exclude '*' --include '*.whl'
          aws s3 cp . "s3://${{ env.s3bucket }}/${{ env.s3wheels_win_amd64_path }}" --recursive

      - name: Upload package
        uses: actions/upload-artifact@v3
        with:
          name: Package (${{ matrix.name }})
          path: ${{ env.package_path }}
          retention-days: 7

      - name: Upload Wheels
        if: matrix.cmake_generator_platform != 'Win32'
        uses: actions/upload-artifact@v3
        with:
          name: Wheels (${{ matrix.name }})
          path: ${{ env.wheels_path }}
          retention-days: 7

  deploy_linux:
    runs-on: ubuntu-latest
    name: ${{ matrix.name }}

    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.name }}
      cancel-in-progress: true
    timeout-minutes: 180
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: Ubuntu 20.04 gcc-10 Release
            image: ubuntu:20.04
            cmake_generator: Ninja
            cmake_build_type: Release
            cmake_defines: -DOPENDAQ_BUILD_DOCUMENTATION=ON -DDAQSIMULATOR_ENABLE_SIMULATOR_APP=ON
            build_documentation: true
            cpack: DEB
            apt_packages: g++-10
            cc: gcc-10
            cxx: g++-10

    container:
      image: ${{ matrix.image }}
      env:
        TZ: Europe/Berlin
        DEBIAN_FRONTEND: noninteractive
        CC: ${{ matrix.cc }}
        CXX: ${{ matrix.cxx }}

    steps:
      - name: Install basic dependencies
        run: |
          apt-get update
          apt-get install -y git openssh-client rename

      - name: Checkout
        uses: actions/checkout@v3

      - name: Install build dependencies
        run: |
          apt-get install -y --no-install-recommends ${{ matrix.apt_packages }} \
            awscli \
            lld ninja-build curl \
            python3-pip python3-dev \
            mono-runtime libmono-system-json-microsoft4.0-cil libmono-system-data4.0-cil \
            libx11-dev libxcursor-dev libxrandr-dev libgl-dev libudev-dev libfreetype6-dev

      - name: Install documentation dependencies
        if: matrix.build_documentation
        run: apt-get install -y --no-install-recommends doxygen graphviz wget zip

      - name: Install latest CMake
        run: pip install cmake

      - name: Configure
        run: |
          mkdir build
          cd build
          cmake -G ${{ matrix.cmake_generator }} --preset ${{ env.cmake_preset }} ${{ matrix.cmake_defines }} -DCI_GIT_BRANCH=${{ github.ref }} -DCMAKE_BUILD_TYPE=${{ matrix.cmake_build_type }} ..

      - name: Build
        working-directory: build
        run: cmake --build .

      - name: Package
        working-directory: build
        run: cpack -C ${{ matrix.cmake_build_type }} -G ${{ matrix.cpack }}

      - name: Get short SHA
        if: github.ref == 'refs/heads/main'
        id: short-sha
        uses: benjlevesque/short-sha@v2.2

      - name: Rename package (main)
        working-directory: ${{ env.package_path_rel }}
        if: github.ref == 'refs/heads/main'
        run: |
          rename 's/_amd64/-ubuntu20.04-x86_64_${{ steps.short-sha.outputs.sha }}/' *.deb
          rename 's/opendaq_/opendaq-/' *.deb

      - name: Rename package
        working-directory: ${{ env.package_path_rel }}
        if: github.ref != 'refs/heads/main'
        run: |
          rename 's/_amd64/-ubuntu20.04-x86_64/' *.deb
          rename 's/opendaq_/opendaq-/' *.deb

      - name: Read openDAQ version
        id: daq_version
        working-directory: .
        run: |
            DAQ_VER=$(cat opendaq_version)
            echo Head openDAQ version: $DAQ_VER
            echo "DAQ_VERSION=$DAQ_VER" >> "$GITHUB_OUTPUT"

      - name: Compress documentation
        if: matrix.build_documentation
        working-directory: build/doc_doxygen/html
        run: zip -r "../../cpp_api_reference.zip" .

      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload package to S3
        working-directory: ${{ env.package_path_rel }}
        run: |
          aws s3 rm s3://${{ env.s3bucket }}/${{ env.s3path }}/  --recursive --exclude '*' --include '*.deb'
          aws s3 cp . s3://${{ env.s3bucket }}/${{ env.s3path }}/ --recursive

      - name: Upload package
        uses: actions/upload-artifact@v3
        with:
          name: Package (${{ matrix.name }})
          path: ${{ env.package_path_rel }}
          retention-days: 7

      - name: Upload documentation to S3
        if: matrix.build_documentation
        working-directory: build
        run: |
          aws s3 rm "s3://${{ env.s3bucket }}/${{ env.s3docpath }}/"  --recursive --exclude '*' --include 'cpp_api_reference.zip'
          aws s3 cp "cpp_api_reference.zip" "s3://${{ env.s3bucket }}/${{ env.s3docpath }}/"

      - name: Upload API reference
        uses: actions/upload-artifact@v3
        with:
          name: API Reference
          path: "build/cpp_api_reference.zip"
          retention-days: 7

      - name: Upload examples to S3
        working-directory: examples
        run: |
          zip -r opendaq-${{ steps.daq_version.outputs.DAQ_VERSION }}-examples.zip cpp python
          aws s3 rm s3://${{ env.s3bucket }}/${{ env.s3path }}/  --recursive --exclude '*' --include '*examples.zip'
          aws s3 cp opendaq-${{ steps.daq_version.outputs.DAQ_VERSION }}-examples.zip s3://${{ env.s3bucket }}/${{ env.s3path }}/

      - name: Upload temporary package for simulator
        uses: actions/upload-artifact@v3
        with:
          name: ${{ env.simulator_package_artifact }}
          path: ${{ env.package_path_rel }}

      - name: Upload simulator app
        uses: actions/upload-artifact@v3
        with:
          name: ${{ env.simulator_app_artifact }}
          path: build/bin/application_simulator

  deploy_linux_wheels:
    runs-on: ubuntu-latest
    name: ${{ matrix.name }}

    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}-${{ matrix.name }}
      cancel-in-progress: true
    timeout-minutes: 180
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: manylinux2014 gcc Release
            image: quay.io/pypa/manylinux2014_x86_64
            cmake_generator: Ninja
            cmake_build_type: Release
            additional_packages:
            cc: gcc
            cxx: g++
            cpack: ZIP

    container:
      image: ${{ matrix.image }}
      env:
        TZ: Europe/Berlin
        CC: ${{ matrix.cc }}
        CXX: ${{ matrix.cxx }}

    steps:
      - name: Install basic dependencies
        run: |
          yum update -y
          yum install -y git awscli

      - name: Checkout
        uses: actions/checkout@v3

      - name: Install build dependencies
        run: |
          yum install -y ${{ matrix.additional_packages }} \
              ninja-build \
              mono-core \
              freetype-devel libudev-devel libX11-devel libXcursor-devel libXrandr-devel

      - name: Create build dir
        run: mkdir build

      - name: Configure and build Python Wheels
        working-directory: build
        run: |
          mkdir wheels
          for version in ${{ env.python_versions }}; do
              echo "Building for Python $version"
              cmake -G "${{ matrix.cmake_generator }}" --preset ${{ env.cmake_preset }} -DCMAKE_BUILD_TYPE=${{ matrix.cmake_build_type }} -DCI_GIT_BRANCH=${{ github.ref }}  -DOPENDAQ_PYTHON_VERSION=$version ..
              cmake --build .
              python$version -m venv venv
              . venv/bin/activate
              pip install numpy pybind11-stubgen
              python${{env.python_version_build}} ../bindings/python/package/build_pip.py -r
              cp -f pip/packages/opendaq*.whl wheels
              deactivate
              rm -rf venv
          done

      - name: Get short SHA
        if: github.ref == 'refs/heads/main'
        id: short-sha
        uses: benjlevesque/short-sha@v2.2

      - name: Rename Wheels (main)
        working-directory: ${{ env.wheels_path }}
        if: github.ref == 'refs/heads/main'
        run: |
          rename "s/-cp/_${{ steps.short-sha.outputs.sha }}-cp/" *.whl

      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload Wheels to S3
        if: github.ref == 'refs/heads/main'
        working-directory: ${{ env.wheels_path }}
        run: |
          aws s3 rm "s3://${{ env.s3bucket }}/${{ env.s3wheels_linux_x86_64_path }}" --recursive --exclude '*' --include '*.whl'
          aws s3 cp . "s3://${{ env.s3bucket }}/${{ env.s3wheels_linux_x86_64_path }}" --recursive

      - name: Upload Wheels
        uses: actions/upload-artifact@v3
        with:
          name: Wheels (${{ matrix.name }})
          path: ${{ env.wheels_path }}
          retention-days: 7

  simulator-build:
    runs-on: ubuntu-latest-4-cores
    name: Simulator build
    needs: [deploy_linux]

    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}
      cancel-in-progress: true
    timeout-minutes: 120
    env:
      simulator_directory: simulator

    defaults:
      run:
        working-directory: ${{ env.simulator_directory }}

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y virtualbox vagrant

      - name: Download package
        uses: actions/download-artifact@v3
        with:
          name: ${{ env.simulator_package_artifact }}
          path: ${{ env.simulator_directory }}

      - name: Download simulator app
        uses: actions/download-artifact@v3
        with:
          name: ${{ env.simulator_app_artifact }}
          path: ${{ env.simulator_directory }}

      - name: Display files in working directory
        run: ls -Rhl

      - name: Read openDAQ version
        id: daq_version
        working-directory: .
        run: |
            DAQ_VER=$(cat opendaq_version)
            echo Head openDAQ version: $DAQ_VER
            echo "DAQ_VERSION=$DAQ_VER" >> "$GITHUB_OUTPUT"

      - name: Get short SHA
        if: github.ref == 'refs/heads/main'
        id: short-sha
        uses: benjlevesque/short-sha@v2.2

      - name: Define simulator name
        id: simulator_name
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ];
          then
            echo "SIMULATOR_NAME=opendaq-${{ steps.daq_version.outputs.DAQ_VERSION }}_${{ env.vm_name }}_${{ steps.short-sha.outputs.sha }}" >> "$GITHUB_OUTPUT"
          else
            echo "SIMULATOR_NAME=opendaq-${{ steps.daq_version.outputs.DAQ_VERSION }}_${{ env.vm_name }}" >> "$GITHUB_OUTPUT"
          fi

      - name: Find binaries and run vagrant
        run: |
          debfiles=( *.deb )
          vagrant --version
          VM_NAME=${{ steps.simulator_name.outputs.SIMULATOR_NAME }} HOME_PATH=$HOME PACKAGE_NAME=${debfiles[0]} vagrant up
          VM_NAME=${{ steps.simulator_name.outputs.SIMULATOR_NAME }} HOME_PATH=$HOME PACKAGE_NAME=${debfiles[0]} vagrant halt

      - name: vboxmanage modify and compact
        run: |
          vboxmanage modifyvm ${{ steps.simulator_name.outputs.SIMULATOR_NAME }} --audio none --uart1 off --nic1 hostonly --hostonlyadapter1 "VirtualBox Host-Only Ethernet Adapter"
          vboxmanage modifymedium disk "${{ steps.simulator_name.outputs.SIMULATOR_NAME }}.vdi" --compact

      - name: vboxmanage check
        run: |
          vboxmanage list vms
          vboxmanage list hostonlyifs
          vboxmanage list hdds

      - name: export VM to .ova appliance
        run: |
          vboxmanage export ${{ steps.simulator_name.outputs.SIMULATOR_NAME }} -o ${{ steps.simulator_name.outputs.SIMULATOR_NAME }}.ova --options manifest,nomacs
          ls -hl ${{ steps.simulator_name.outputs.SIMULATOR_NAME }}.ova

      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload package to S3
        run: |
          aws s3 rm s3://${{ env.s3bucket }}/${{ env.s3simulatorpath }}/  --recursive --exclude '*' --include '*.ova'
          aws s3 cp ${{ steps.simulator_name.outputs.SIMULATOR_NAME }}.ova s3://${{ env.s3bucket }}/${{ env.s3simulatorpath }}/

      - name: Upload OVA image
        uses: actions/upload-artifact@v3
        with:
          name: ${{ steps.simulator_name.outputs.SIMULATOR_NAME }}-ova-image
          path: simulator/${{ steps.simulator_name.outputs.SIMULATOR_NAME }}.ova
          retention-days: 7

      - name: Delete unused artifacts
        uses: geekyeggo/delete-artifact@v2
        with:
          name: |
            ${{ env.simulator_app_artifact }}
            ${{ env.simulator_package_artifact }}

  build_documentation:
    runs-on: ubuntu-latest
    name: Build SDK Documentation
    needs: [deploy_linux]
    timeout-minutes: 4
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '16'

      - name: Install Antora
        run: npm i antora

      - name: Install Antora extensions
        run: |
          npm i @asciidoctor/tabs
          npm i @springio/antora-extensions

      - name: Run Antora
        run: >
          [ "refs/heads/main" != "${{ github.ref }}" ] && npx antora antora-playbook.yml
          || (export DAQ_DEV_WEBSITE=docs-dev; npx antora antora-playbook-dev.yml)

      - name: Compress Documentation
        working-directory: ${{ github.workspace }}/build/site/
        run: zip -r ${{ github.workspace }}/build/user_guide.zip .

      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload Documentation to S3
        run: |
          aws s3 rm "s3://${{ env.s3bucket }}/${{ env.s3docpath }}/"  --recursive --exclude '*' --include 'user_guide.zip'
          aws s3 cp ${{ github.workspace }}/build/user_guide.zip "s3://${{ env.s3bucket }}/${{ env.s3docpath }}/"

      - name: Call the API to deploy the documentation
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ];
          then
            wget ${{ secrets.DEPLOY_DEV_DOCUMENTATION_URL_AND_TOKEN }}
          else
            wget ${{ secrets.DEPLOY_DOCUMENTATION_URL_AND_TOKEN }}
          fi

      - uses: actions/upload-artifact@v3
        with:
          name: openDAQ_SDK_User_Guide
          path: ${{ github.workspace }}/build/user_guide.zip
          retention-days: 7
